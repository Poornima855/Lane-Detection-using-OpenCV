# -*- coding: utf-8 -*-
"""Lane Detection using OpenCV - ADAS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GYlD2sYI4hyGOs-XG_0YaGd4ouVlZJQU

## Key Steps :

1. Convert frame to grayscale – simplifies image for processing.

2. Apply Gaussian blur – reduces noise.

3. Use Canny edge detection – highlights lane edges.

4. Mask region of interest – focuses on road area.

5. Detect lines with Hough Transform – identifies lane lines.

6. Draw and overlay lines on original frame – visualizes detected lanes.

7. Process each video frame – apply pipeline frame-by-frame.

8. Save output video – write processed frames to file.
"""

pip install opencv-python numpy

from google.colab import files
uploaded = files.upload()

"""## Some video to test"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

def grayscale(img):
    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

def canny(img, low_threshold=50, high_threshold=150):
    return cv2.Canny(img, low_threshold, high_threshold)

def gaussian_blur(img, kernel_size=5):
    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)

def region_of_interest(img):
    height = img.shape[0]
    polygons = np.array([
        [(100, height), (img.shape[1]-100, height), (img.shape[1]//2, height//2)]
    ])
    mask = np.zeros_like(img)
    cv2.fillPoly(mask, polygons, 255)
    return cv2.bitwise_and(img, mask)

def display_lines(img, lines):
    line_img = np.zeros_like(img)
    if lines is not None:
        for line in lines:
            for x1, y1, x2, y2 in line:
                cv2.line(line_img, (x1, y1), (x2, y2), (0, 255, 0), 10)
    return line_img

def hough_lines(img):
    return cv2.HoughLinesP(img, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)

def add_weighted(img1, img2, α=0.8, β=1.0, λ=0.0):
    return cv2.addWeighted(img1, α, img2, β, λ)

def process_frame(frame):
    gray = grayscale(frame)
    blur = gaussian_blur(gray)
    edges = canny(blur)
    cropped = region_of_interest(edges)
    lines = hough_lines(cropped)
    line_img = display_lines(frame, lines)
    return add_weighted(frame, line_img)

# ----- PROCESS VIDEO -----

input_path = "lanes_clip.mp4"
cap = cv2.VideoCapture(input_path)

# Get video properties
width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps    = cap.get(cv2.CAP_PROP_FPS)

# Define video writer
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('output_lanes.mp4', fourcc, fps, (width, height))

frame_count = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    processed = process_frame(frame)
    out.write(processed)

    # Optional: show every 50th frame
    if frame_count % 50 == 0:
        print(f"Processing frame: {frame_count}")
        cv2_imshow(processed)

    frame_count += 1

cap.release()
out.release()
print("✅ Video processing complete. Saved as 'output_lanes.mp4'")

"""Not efficient due to missed lanes

## IISc lanes short test video
"""

from google.colab import files
uploaded = files.upload()

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

def grayscale(img):
    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

def canny(img, low_threshold=50, high_threshold=150):
    return cv2.Canny(img, low_threshold, high_threshold)

def gaussian_blur(img, kernel_size=5):
    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)

def region_of_interest(img):
    height = img.shape[0]
    polygons = np.array([
        [(100, height), (img.shape[1]-100, height), (img.shape[1]//2, height//2)]
    ])
    mask = np.zeros_like(img)
    cv2.fillPoly(mask, polygons, 255)
    return cv2.bitwise_and(img, mask)

def display_lines(img, lines):
    line_img = np.zeros_like(img)
    if lines is not None:
        for line in lines:
            for x1, y1, x2, y2 in line:
                cv2.line(line_img, (x1, y1), (x2, y2), (0, 255, 0), 10)
    return line_img

def hough_lines(img):
    return cv2.HoughLinesP(img, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)

def add_weighted(img1, img2, α=0.8, β=1.0, λ=0.0):
    return cv2.addWeighted(img1, α, img2, β, λ)

def process_frame(frame):
    gray = grayscale(frame)
    blur = gaussian_blur(gray)
    edges = canny(blur)
    cropped = region_of_interest(edges)
    lines = hough_lines(cropped)
    line_img = display_lines(frame, lines)
    return add_weighted(frame, line_img)

# ----- PROCESS VIDEO -----

input_path = "/content/test_clip.mp4"
cap = cv2.VideoCapture(input_path)

# Get video properties
width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps    = cap.get(cv2.CAP_PROP_FPS)

# Define video writer
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('output_lanes_test.mp4', fourcc, fps, (width, height))

frame_count = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    processed = process_frame(frame)
    out.write(processed)

    # Optional: show every 50th frame
    if frame_count % 50 == 0:
        print(f"Processing frame: {frame_count}")
        cv2_imshow(processed)

    frame_count += 1

cap.release()
out.release()
print("✅ Video processing complete. Saved as 'output_lanes_test.mp4'")

"""Not much effecient due to different lightings and shadows etc."""

